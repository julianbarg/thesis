\subsection{Chapter 1: Stuck on Innovation}

Organizational learning comes down to choices. Firms can either invest in improving existing technology, or develop new technology \citep{March1991}. Investing in the "wrong" technology can lead to technological lock-ins \citep{Levinthal1993}. The actors in the pipeline industry have selected a number of technological solutions to resolve their most pressing issue. When a pipeline spill occurs, the oil quickly infiltrates the soil and seeps into the groundwater.\footnote{The infiltration depth in sand is assumed to be over 10m in the first day alone \citep{Bonvicini2015}.} The environmental degradation caused by oil affects the local environment, and the local populace, too: a 2019 sibling comparison study on oil spills in Nigeria found that in localities that are affected by oil spills, for every 1,000 live births, an additional 38.3 neonatal deaths occur\citep{Bruederle2019}. % Potentially add impact of spills on industry? Stigmatized industry.

In their fight against pipeline spills, pipeline operators employ a variety of technologies, such as smart pigs, leak detection systems, and SCADA systems. Smart pigs, while traveling through the pipes, utilize electromagnetic flux or ultrasonic probing to assess corrosion or mechanical damages to the pipe \citep{Singh2017-7}. Internal leak detection systems measure the flow of oil at two points A and B to detect any loss in between those points. External leak detection systems detect signs of escaping hydrocarbons, and include acoustic, hydrocarbon, and temperature sensors. \citep{Shaw2012}. SCADA systems are systems that allow an operator remotely monitor and operate lines. The operator typically sees on his screen charts of the flow at different points, can open and close valves, and startup or shutdown delivery of oil. Alarms from leak detection systems of the line are also displayed to the SCADA operator.\footnote{Larger pipeline companies operate control centers where all lines in a region are managed. Operators usually operate multiple SCADA systems at once, and more experienced employees supervise the operators. Control centers are operated in formal hierarchy, where for certain operations (such as clearing an alarm), a SCADA operator will require the go-ahead from a supervisor. See \citet{NTSB2012} for an in-depth description of an Enbridge control center in Edmonton as of 2012.}

The high technology character of leak detection stands in contrast to the experienced reality of pipeline spills. A 2012 study commissioned by the Pipeline and Hazardous Materials Safety Administration (PHMSA) of onshore pipeline spills that occurred over a 19 month period, SCADA systems assisted in less than 25\% of cases with the detection and confirmation of the spill \citep[p. 3-33]{Shaw2012}. In only 17\% of cases was the operator or SCADA system listed as the initial identifier of the leak, while the public or emergency responders identified 30\% of leaks \citep[p. 3-39]{Shaw2012}. Why do the great learning efforts by pipeline operators fail to deliver the safety improvements that one would expect to see? A 2012 report prepared by the National Transportation Safety Board (NTSB) on the Kalamazoo River oil spill provides a good starting point for understanding the problem. A regional manager of Enbridge is quotes as saying: "...I'm not convinced [that there is a problem]. We haven't had any phone calls. I mean it's perfect weather out here--if it's a rupture someone's going to notice that, you know and smell it" \citep[p. 100]{NTSB2012}.

This chapter uses the quantitative data from PHMSA to demonstrate how existing problems are addressed, following major spills that catch the attention of the industry, the regulator, and the public. That empirical observation is contrasted with the character of the two challenges that remain: (1) as holes are plugged, new unique sources of spills, for example climate change-related weather changes, emerge. (2) Both the "human factor" and the "organizational factor" are pervasive factors that yet to be completely eliminate as sources of error in any context. Overall, the geographic, technological, and organizational complexity of pipelines have led to the current situation, a quasi-standstill in the sector for refined oil. Crude oil pipelines on the other hand still have some potential for improvements, as simple and fundamental problem of this sector-- the corrosiveness of the commodity-- is addressed through new coatings, and cathodic protection.

The quantitative section of this chapter uses a sample consisting of the 100 largest operators in the pipeline industry over the period from 2004 through 2019. The data that is available from PHMSA is matched and supplemented with data from Compustat. This quantitative section focuses on improvements over time in organizations affected by a specific source of incidents, and a reduction in certain causes of spills. Some qualitative data supplements the quantitative analysis by showcasing the processes of population level learning \citep{Miner1999}, especially for crude pipelines. The qualitative section then uses archival data to explore a sample of 15 major pipeline spills since 1986 to contrast the specificity of learning in the quantitative analysis with the complexity of the systems that the incidents occur in, and the complex interactions that lead to spills. The sample of 15 spills includes the top three spills with regard to spill volume, net loss (spill volume minus volume recovered), number of injuries, number of fatalities, and property damage. This sampling method ensure both a variety in the type of spills, and a good availability of archival data.

This chapter contributes to the literature on knowledge-based learning by exploring the topic of a bottomed-out learning curve through raising the issue of aggregate and specific learning. The chapter also contributes to the debate on industry resource use: it discusses both the historical development and the potential future reduction (or lack thereof) of an industry's environmental footprint. Whereas in the past, improvements were made through incremental learning in the form of development of new technology, the analysis suggest that further improvements may only be possible through bold, maybe costly new choices, including a change of industry for some companies.

%Our qualitative analysis reveals that pipeline spills have all the hallmarks of normal accidents in complex systems \citep{Perrow1984}. Almost no two serious spills are alike, and the causes are as complex as the diverse political and physical environments that is the United States. Here, organizational learning is at an impasse. When efforts is made, and learning takes place, why do we not observe corresponding results? \citet{Levitt1988} propose that there are limitations to learning by doing. In those cases, learning cannot be disaggregated into its components. Instead, we need to look at the technological choices and determine whether an organization or industry has ended up in a competency trap \citep{Levitt1988}. An important factor for diagnosing this issue are feedback mechanisms: at the population level, is the problem diagnosed, or not? If in an industry the lack of learning goes unnoticed or is not addressed on a population level, even if learning takes place on a case-by-case basis, aggregate learning may not take place {MarchOlsen}.   

%With this article, we provide an additional perspective to the learning literature. Our interpretation of the data puts into question the notion of aggregate improvements through incremental, smaller scale learning. Instead, there are more substantive, technological improvements to be made, that sometimes cannot be attained through regular learning mechanisms. In those cases, a big picture perspective on the problem or goal is necessary to made a difference.

%   Other contribution: write something on learning that fills the gap created by publication bias.

%	Hints at a problem in the learning literature. Focusing on incremental improvement.

%   Claim quantitatie data as part of initial qualitative research? We looked at 10 major spills and x years of spill data, to understand how population-level learning works. Also, claim data on population level learning as part of the research.

%	Qualitative research approach--select spills--move through spills until motives saturated.

%	Limited ability to triangulate--but that is fine because our qualitative results are quite robust, and not too complex--little chance they are wrong.

%	Another omission that we decided on for this article are flaws in the environmental feedback mechanism, akin to those predicted in \citet{March1975}. Pipeline operators are well-insulated from the consequences of their actions, as the regulator (PHMSA) is understaffed and generally gives pipeline operators the benefit of doubt [provide evidene from NTSB].

